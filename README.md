# ğŸ§  News Credibility AI

An end-to-end AI-powered web application that detects whether a news article is **Real or Fake** using Natural Language Processing (NLP) and Machine Learning.

Paste any news text or drop a URL â€” our system scrapes, analyzes, and returns a credibility verdict with a confidence score in seconds.

---

## ğŸš€ Live Features

- ğŸ“ **Text Input** â€” Paste raw news article text for instant analysis
- ğŸŒ **URL Input** â€” Enter any news URL; the system auto-scrapes the article
- ğŸ“Š **Confidence Score** â€” See *how confident* the AI is (e.g., 94.7%)
- âš¡ **Real-time Step Animation** â€” Live progress feedback during analysis
- ğŸ·ï¸ **Clear Verdict** â€” `Real News` or `Fake News` result card

---

## ğŸ—ï¸ Architecture

```
User (Browser)
     â†•  HTTP
React Frontend  (Vite + React)
     â†•  REST API  POST /predict
FastAPI Backend  (Python)
     â”œâ”€â”€ scraper.py          â†’ Extracts article text from URLs (newspaper3k)
     â”œâ”€â”€ preprocessing.py    â†’ NLP cleaning pipeline (NLTK + regex)
     â”œâ”€â”€ model.pkl           â†’ Trained Logistic Regression model
     â””â”€â”€ vectorizer.pkl      â†’ Fitted TF-IDF vectorizer
```

---

## ğŸ¤– Machine Learning Pipeline

The full ML workflow is documented across 4 Jupyter notebooks:

| Notebook | Description |
|---|---|
| `01_data_exploration.ipynb` | EDA â€” class balance, word frequencies, visualizations |
| `02_data_preprocessing.ipynb` | Text cleaning â€” lowercasing, regex, tokenization, stop-word removal |
| `03_feature_extraction_and_model.ipynb` | TF-IDF vectorization + Logistic Regression training |
| `04_model_evaluation.ipynb` | Accuracy, Precision, Recall, F1-Score, Confusion Matrix, ROC-AUC |

### Key Design Decisions

- **TF-IDF** converts text into numerical feature vectors (10,000 features)
- **Logistic Regression** (`C=2.0`, `class_weight='balanced'`) chosen for speed, interpretability, and probability output
- **80/20 train-test split**
- The **exact same preprocessing pipeline** used during training runs in production â€” zero training-serving skew

---

## ğŸ› ï¸ Tech Stack

### Backend
| Tool | Purpose |
|---|---|
| FastAPI | REST API framework |
| scikit-learn | Logistic Regression + TF-IDF |
| NLTK | Tokenization & stop-word removal |
| newspaper3k | Article scraping from URLs |
| joblib | Model serialization (`.pkl`) |
| uvicorn | ASGI server |

### Frontend
| Tool | Purpose |
|---|---|
| React 18 | UI framework |
| Vite | Build tool & dev server |
| Axios | HTTP client for API calls |
| Lucide React | Icons |

---

## ğŸ“ Project Structure

```
news-credibility-ai/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py              # FastAPI app â€” main prediction endpoint
â”‚   â”œâ”€â”€ preprocessing.py    # NLP text cleaning pipeline
â”‚   â”œâ”€â”€ scraper.py          # URL article extractor
â”‚   â”œâ”€â”€ model.pkl           # Trained ML model
â”‚   â”œâ”€â”€ vectorizer.pkl      # Fitted TF-IDF vectorizer
â”‚   â”œâ”€â”€ requirements.txt    # Python dependencies
â”‚   â””â”€â”€ render.yaml         # Cloud deployment config (Render)
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx         # Main React component
â”‚   â”‚   â””â”€â”€ index.css       # Global styles
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”œâ”€â”€ notebook/
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_data_preprocessing.ipynb
â”‚   â”œâ”€â”€ 03_feature_extraction_and_model.ipynb
â”‚   â””â”€â”€ 04_model_evaluation.ipynb
â”œâ”€â”€ data/                   # Raw dataset (tracked via Git LFS)
â””â”€â”€ artifacts/              # Saved test sets (X_test.pkl, y_test.pkl)
```

---

## âš™ï¸ Setup & Running Locally

### Prerequisites
- Python 3.9+
- Node.js 18+

---

### 1. Clone the Repository

```bash
git clone https://github.com/your-username/news-credibility-ai.git
cd news-credibility-ai
```

---

### 2. Backend Setup

```bash
cd backend

# Create and activate virtual environment
python -m venv venv
source venv/bin/activate        # macOS/Linux
# venv\Scripts\activate         # Windows

# Install dependencies
pip install -r requirements.txt

# Start the API server
uvicorn app:app --reload
```

The backend will start at **http://127.0.0.1:8000**

---

### 3. Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Start the dev server
npm run dev
```

The frontend will start at **http://localhost:5173**

---

## ğŸŒ API Reference

### `POST /predict`

Predicts whether a news article is Real or Fake.

**Request Body** (JSON):
```json
{
  "text": "Paste your article text here...",
  "url": ""
}
```
or
```json
{
  "text": "",
  "url": "https://example.com/news-article"
}
```

**Response**:
```json
{
  "status": "success",
  "prediction": "Fake News",
  "confidence_score": 76.28,
  "input_source": "text",
  "text_length": 312,
  "message": "Credibility analysis completed successfully."
}
```

### `GET /`

Health check endpoint.

```json
{ "message": "News Credibility Analysis API is running", "status": "healthy" }
```

---

## ğŸ” How It Works â€” Prediction Flow

1. **Input received** â€” raw text or a URL
2. **Scrape** (if URL) â€” `newspaper3k` extracts article title + body
3. **Validate** â€” must have â‰¥ 10 words
4. **Preprocess** â€” lowercase â†’ remove punctuation â†’ tokenize â†’ remove stop-words
5. **Vectorize** â€” transform using saved TF-IDF vectorizer (10,000 features)
6. **Predict** â€” run saved Logistic Regression model
7. **Return** â€” label (`Real News` / `Fake News`) + confidence score

---

## â˜ï¸ Deployment

### Backend â€” [Render](https://render.com)
A `render.yaml` is included in the `backend/` folder for one-click deployment.

### Frontend â€” [Vercel](https://vercel.com) / [Netlify](https://netlify.com)
Set the environment variable:
```
VITE_API_URL=https://your-backend-url.onrender.com
```

---

## ğŸ“¦ Dataset

The dataset is stored using **Git LFS** due to its size (~234 MB).
It contains thousands of labeled news articles with `title`, `text`, and `label` (Real/Fake) columns.

To pull the dataset after cloning:
```bash
git lfs pull
```

---

## ğŸ‘¥ Team

Built as a group project â€” contributions span data science, ML engineering, backend API development, and frontend UI.

---

## ğŸ“„ License

This project is for educational purposes.